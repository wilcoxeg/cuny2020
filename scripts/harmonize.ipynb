{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data harmonization\n",
    "\n",
    "This notebook harmonizes (aligns) human reading time data from multiple corpora with language model surprisal data. This is necessary because the various reading time corpora and language models all deploy different preprocessing/tokenization procedures.\n",
    "\n",
    "This notebook reads from the following directories:\n",
    "\n",
    "- `data/model_results/<architecture>/<corpus>_<architecture>_<training-corpus>_<seed>.csv` contains language model surprisal data for language model `<architecture>`, trained on `<training-corpus>` with seed `<seed>` and evaluated on a reading time corpus `<corpus>`\n",
    "- `data/human_rts/<corpus>/*.txt` contains human reading time data, as produced by the script `scripts/average_sprs_script.Rmd`\n",
    "\n",
    "This notebook writes to the file `data/harmonized_data.csv` the following table:\n",
    "\n",
    "| code | word | surprisal | psychometric | corpus | model | training | seed | len | freq |\n",
    "| -- | -- | -- | -- | -- | -- | -- | -- | -- | -- |\n",
    "| unique integer identifying a token within a test corpus | token | model surprisal estimate | human psychometric (e.g. firstpass RT, SPR measure) for token | test corpus | model architecture name | model training corpus | model training seed | token length | token log-frequency |\n",
    "\n",
    "This can then be read by the main analysis notebook, `notebooks/analysis.Rmd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "import regex as re\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import harmonize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load word frequency statistics for control features\n",
    "word_freq = Counter()\n",
    "with open(\"../data/wikitext-2_train_vocab.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        token, freq = line.strip().split(\"\\t\")\n",
    "        word_freq[token] = int(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatches = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c01aa6a98f4d7fbbb27026c86c9fc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Harmonizing models', max=4.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b5c7519eefb48e4a79b37a96165bc43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Test files', max=80.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54981c4425940c3976437694cd0ae91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Test files', max=4.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "794f90a59ee24b2daf15f462652f2a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Test files', max=4.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b6b1637f014b119c60bd5f7222cee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Test files', max=180.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc9c93c1676425fb48364b297d2de88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Test files', max=9.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d759839cada346628815d37b0f670542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Test files', max=9.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53662f0620614397a69ac875f0550e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Test files', max=180.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb8ad6e5702477e9e363ff45c30736b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Test files', max=9.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f52a5b9870c4fdb9d7bb66482c29c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Test files', max=10.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23e41a8bcd843e2ae7f69c6c3ee86f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Test files', max=140.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70af6b34d6d4ba0a64d6913087f3784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Test files', max=7.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "917d26a3d7a24743ad83800524127336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Test files', max=7.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def merge_model_results(log_target_code=None):\n",
    "    mismatches = Counter()\n",
    "    final_df = []\n",
    "    \n",
    "    models = [f for f in os.listdir(\"../data/model_results\") if not f.startswith(\".\")]\n",
    "    for m in tqdm(models, desc=\"Harmonizing models\"):\n",
    "        #tqdm.write(\"Harmonizing results for \" + m)\n",
    "        test_corpus = [f for f in os.listdir(\"../data/model_results/\" + m) if not f.startswith(\".\")]\n",
    "        for tc in test_corpus:\n",
    "            test_files = [f for f in os.listdir(\"../data/model_results/\" + m + \"/\" + tc) if not f.startswith(\".\")]\n",
    "            \n",
    "            for tf in tqdm(test_files, desc=\"Test files\"):\n",
    "                if tf == \"UNKS\":\n",
    "                    print(\"TODO: UNKS\")\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    tf = tf.split(\"_\")\n",
    "                    test_filename = tf[0]\n",
    "                    model_architecture = tf[1]\n",
    "                    training_data = tf[2]\n",
    "                    seed = tf[3].replace(\".csv\", \"\")\n",
    "                except:\n",
    "                    print(tf)\n",
    "                \n",
    "                model_results = \"_\".join([test_filename, model_architecture, training_data, seed])\n",
    "                model_path = \"/\".join([\"../data/model_results\", m, tc, model_results])\n",
    "                model_results = pd.read_csv(model_path+\".csv\", sep=\"\\t\")\n",
    "                \n",
    "                # Special handling for the Dundee corpus\n",
    "                if tc == \"dundee\":\n",
    "                    gold_test_filename = test_filename.replace(\"wrdp\", \"\") + \"_avg\"\n",
    "                    gold_standard = pd.read_csv(\"../data/human_rts/\" + tc + \"/\" + gold_test_filename + \".txt\", sep=\"\\t\",\n",
    "                                                names=[\"word\", \"surprisal\"])\n",
    "                    gold_standard.insert(0, 'code', range(0,len(gold_standard)))\n",
    "                    gold_standard[\"code\"] = gold_standard[\"code\"] + int(test_filename.replace(\"tx\", \"\").replace(\"wrdp\", \"\")) * 10000\n",
    "                elif tc == \"bnc-brown\":\n",
    "                    gold_standard = pd.read_csv(\"../data/human_rts/\" + tc + \"/\" + test_filename + \".csv\", sep=\",\",\n",
    "                                                usecols=[\"code\", \"word\", \"psychometric\"])\n",
    "                    \n",
    "                    # Model tokenization differs a little bit here.\n",
    "                    model_results.token = model_results.token.str.replace(\"``\", '\"')\n",
    "                    model_results.token = model_results.token.str.replace(\"''\", '\"')\n",
    "                elif tc == \"natural-stories\":\n",
    "                    gold_standard = pd.read_csv(\"../data/human_rts/\" + tc + \"/\" + test_filename + \".txt\", sep=\"\\t\")\n",
    "                \n",
    "                # PTB-de-process model results\n",
    "                model_results.token = model_results.token.str.replace(\"-LRB-\", \"(\")\n",
    "                model_results.token = model_results.token.str.replace(\"-RRB-\", \")\")\n",
    "                model_results.token = model_results.token.str.replace(\"-LSB-\", \"[\")\n",
    "                model_results.token = model_results.token.str.replace(\"-RSB-\", \"]\")\n",
    "                \n",
    "                model_results = [tuple(x)[2:4] for x in model_results.values.tolist()]\n",
    "                gold_standard = [tuple(x) for x in gold_standard.values.tolist()]\n",
    "                \n",
    "                harmonized_results, mismatches_i = harmonize.harmonize_rows(gold_standard, model_results,\n",
    "                                                                            log_target_code=log_target_code)\n",
    "                mismatches += mismatches_i\n",
    "                \n",
    "                result = [tuple((x[2], x[0], x[1], x[4], tc, model_architecture, training_data, seed, len(x[0]), math.log(word_freq[x[0]]+1))) for x in harmonized_results]\n",
    "                final_df.extend(result)\n",
    "                \n",
    "    df = pd.DataFrame(final_df)\n",
    "    df.columns = [\"code\", \"word\", \"surprisal\", \"psychometric\", \"corpus\", \"model\", \"training\", \"seed\", \"len\", \"freq\"]\n",
    "    df.head()\n",
    "    df.to_csv(\"../data/harmonized_results.csv\")\n",
    "    return df, mismatches\n",
    "\n",
    "non_issue_mismatches = [\n",
    "    ## dundee\n",
    "    # comma-separated list (lots of punctuation joins)\n",
    "    172179, 50578, 180516, 91736, 102630,\n",
    "    \n",
    "    # lotsa punct\n",
    "    200203, 160452, 180430,\n",
    "    \n",
    "    # lotsa unk\n",
    "    60765, 60766, 21970,\n",
    "    \n",
    "    # punct + unk\n",
    "    131873, 51548, 142006, 182019, 112194,\n",
    "    \n",
    "    ## natural stories\n",
    "    # lotsa unk\n",
    "    60391,\n",
    "    # unk+punct\n",
    "    60676,\n",
    "    \n",
    "    # bnc-brown\n",
    "    # punct\n",
    "    20165, 20178, 26533, 29273,\n",
    "    # punct and unks\n",
    "    32117, 17107,\n",
    "]\n",
    "for code in non_issue_mismatches:\n",
    "    del mismatches[code]\n",
    "try:\n",
    "    to_log = mismatches.most_common(1)[0][0]\n",
    "except:\n",
    "    to_log = None\n",
    "df, mismatches = merge_model_results(to_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({172179: 29,\n",
       "         131873: 14,\n",
       "         50578: 24,\n",
       "         51548: 14,\n",
       "         160452: 8,\n",
       "         180516: 24,\n",
       "         60766: 6,\n",
       "         180430: 8,\n",
       "         182019: 8,\n",
       "         200203: 20,\n",
       "         112194: 8,\n",
       "         142006: 14,\n",
       "         21970: 8,\n",
       "         102630: 8,\n",
       "         60765: 14,\n",
       "         91736: 14,\n",
       "         60391: 13,\n",
       "         60676: 8,\n",
       "         26533: 30,\n",
       "         32117: 30,\n",
       "         17107: 9,\n",
       "         29273: 9})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>word</th>\n",
       "      <th>surprisal</th>\n",
       "      <th>psychometric</th>\n",
       "      <th>corpus</th>\n",
       "      <th>model</th>\n",
       "      <th>training</th>\n",
       "      <th>seed</th>\n",
       "      <th>len</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140000</td>\n",
       "      <td>Lesley</td>\n",
       "      <td>25.244897</td>\n",
       "      <td>286.375000</td>\n",
       "      <td>dundee</td>\n",
       "      <td>5gram</td>\n",
       "      <td>bllip-md</td>\n",
       "      <td>1111</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140002</td>\n",
       "      <td>a</td>\n",
       "      <td>5.052998</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>dundee</td>\n",
       "      <td>5gram</td>\n",
       "      <td>bllip-md</td>\n",
       "      <td>1111</td>\n",
       "      <td>1</td>\n",
       "      <td>10.495626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140003</td>\n",
       "      <td>51-year-old</td>\n",
       "      <td>12.149018</td>\n",
       "      <td>334.300000</td>\n",
       "      <td>dundee</td>\n",
       "      <td>5gram</td>\n",
       "      <td>bllip-md</td>\n",
       "      <td>1111</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140004</td>\n",
       "      <td>from</td>\n",
       "      <td>8.795982</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>dundee</td>\n",
       "      <td>5gram</td>\n",
       "      <td>bllip-md</td>\n",
       "      <td>1111</td>\n",
       "      <td>4</td>\n",
       "      <td>9.130214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140006</td>\n",
       "      <td>explains</td>\n",
       "      <td>12.865601</td>\n",
       "      <td>252.875000</td>\n",
       "      <td>dundee</td>\n",
       "      <td>5gram</td>\n",
       "      <td>bllip-md</td>\n",
       "      <td>1111</td>\n",
       "      <td>8</td>\n",
       "      <td>3.988984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691369</th>\n",
       "      <td>35749</td>\n",
       "      <td>been</td>\n",
       "      <td>3.947763</td>\n",
       "      <td>284.739583</td>\n",
       "      <td>bnc-brown</td>\n",
       "      <td>gpt-2</td>\n",
       "      <td>bllip-xs-gptbpe</td>\n",
       "      <td>1581807512</td>\n",
       "      <td>4</td>\n",
       "      <td>8.090709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691370</th>\n",
       "      <td>35750</td>\n",
       "      <td>in</td>\n",
       "      <td>5.606664</td>\n",
       "      <td>288.440417</td>\n",
       "      <td>bnc-brown</td>\n",
       "      <td>gpt-2</td>\n",
       "      <td>bllip-xs-gptbpe</td>\n",
       "      <td>1581807512</td>\n",
       "      <td>2</td>\n",
       "      <td>10.714040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691371</th>\n",
       "      <td>35751</td>\n",
       "      <td>precisely</td>\n",
       "      <td>16.519783</td>\n",
       "      <td>324.473750</td>\n",
       "      <td>bnc-brown</td>\n",
       "      <td>gpt-2</td>\n",
       "      <td>bllip-xs-gptbpe</td>\n",
       "      <td>1581807512</td>\n",
       "      <td>9</td>\n",
       "      <td>2.564949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691372</th>\n",
       "      <td>35752</td>\n",
       "      <td>such</td>\n",
       "      <td>11.342088</td>\n",
       "      <td>325.680833</td>\n",
       "      <td>bnc-brown</td>\n",
       "      <td>gpt-2</td>\n",
       "      <td>bllip-xs-gptbpe</td>\n",
       "      <td>1581807512</td>\n",
       "      <td>4</td>\n",
       "      <td>7.368340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691373</th>\n",
       "      <td>35753</td>\n",
       "      <td>dangerous</td>\n",
       "      <td>13.921815</td>\n",
       "      <td>432.996667</td>\n",
       "      <td>bnc-brown</td>\n",
       "      <td>gpt-2</td>\n",
       "      <td>bllip-xs-gptbpe</td>\n",
       "      <td>1581807512</td>\n",
       "      <td>9</td>\n",
       "      <td>4.094345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1691374 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           code         word  surprisal  psychometric     corpus  model  \\\n",
       "0        140000       Lesley  25.244897    286.375000     dundee  5gram   \n",
       "1        140002            a   5.052998    224.000000     dundee  5gram   \n",
       "2        140003  51-year-old  12.149018    334.300000     dundee  5gram   \n",
       "3        140004         from   8.795982    198.000000     dundee  5gram   \n",
       "4        140006     explains  12.865601    252.875000     dundee  5gram   \n",
       "...         ...          ...        ...           ...        ...    ...   \n",
       "1691369   35749         been   3.947763    284.739583  bnc-brown  gpt-2   \n",
       "1691370   35750           in   5.606664    288.440417  bnc-brown  gpt-2   \n",
       "1691371   35751    precisely  16.519783    324.473750  bnc-brown  gpt-2   \n",
       "1691372   35752         such  11.342088    325.680833  bnc-brown  gpt-2   \n",
       "1691373   35753    dangerous  13.921815    432.996667  bnc-brown  gpt-2   \n",
       "\n",
       "                training        seed  len       freq  \n",
       "0               bllip-md        1111    6   0.000000  \n",
       "1               bllip-md        1111    1  10.495626  \n",
       "2               bllip-md        1111   11   0.000000  \n",
       "3               bllip-md        1111    4   9.130214  \n",
       "4               bllip-md        1111    8   3.988984  \n",
       "...                  ...         ...  ...        ...  \n",
       "1691369  bllip-xs-gptbpe  1581807512    4   8.090709  \n",
       "1691370  bllip-xs-gptbpe  1581807512    2  10.714040  \n",
       "1691371  bllip-xs-gptbpe  1581807512    9   2.564949  \n",
       "1691372  bllip-xs-gptbpe  1581807512    4   7.368340  \n",
       "1691373  bllip-xs-gptbpe  1581807512    9   4.094345  \n",
       "\n",
       "[1691374 rows x 10 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
